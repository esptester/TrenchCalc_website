# 3D LiDAR Annotation System

Complete 3D point cloud annotation tool for labeling LiDAR scans for machine learning training.

## üéØ Overview

This is a **complete rebuild** of the annotation system for 3D LiDAR data. Unlike the old 2D image annotation tool (`annotation.html`), this new system handles:

- **3D point clouds** (PLY, PCD, binary formats)
- **Photo-guided selection** (click photo ‚Üí select 3D points)
- **Multi-class labeling** (ground, pipe, shoring, person, equipment, air)
- **Auto-detection** (RANSAC cylinder/plane fitting)
- **Professional UI** (dark theme, responsive, accessible)

## üìÅ File Structure

```
TrenchCalc_website/
‚îú‚îÄ‚îÄ lidar-annotation.html          # Main annotation interface
‚îú‚îÄ‚îÄ annotation.html                # OLD 2D tool (keep for backward compatibility)
‚îî‚îÄ‚îÄ js/annotation/
    ‚îú‚îÄ‚îÄ point-cloud-loader.js      # PLY/PCD/binary loader
    ‚îú‚îÄ‚îÄ labeler.js                 # Label management
    ‚îú‚îÄ‚îÄ ransac-helpers.js          # Auto-detection algorithms
    ‚îî‚îÄ‚îÄ submitter.js               # Backend API integration
```

## üöÄ Features

### Core Functionality

‚úÖ **3D Point Cloud Loading**
- Supports PLY, PCD, binary formats
- Automatic format detection
- Efficient streaming for large datasets
- Color support (RGB per point)

‚úÖ **Photo-Guided Annotation**
- Side-by-side photo + 3D view
- Click on photo ‚Üí highlights in 3D
- Multiple photos per scan
- Camera pose alignment

‚úÖ **Labeling System**
- 7 classes: ground, pipe, headwall, shoring, person, equipment, air
- Color-coded visualization
- Point selection (click, drag, lasso)
- Label statistics and counts

‚úÖ **Auto-Detection**
- RANSAC cylinder fitting for pipes
- RANSAC plane fitting for ground/surfaces
- Confidence scoring
- Inlier/outlier detection

‚úÖ **Backend Integration**
- REST API: GET /annotation/tasks/next
- REST API: POST /annotation/tasks/{id}/labels
- Authentication (Bearer token)
- Task queue management

‚úÖ **Professional UI**
- Dark theme optimized for 3D work
- Responsive layout
- Loading states and progress
- Real-time FPS counter
- Keyboard shortcuts

## üõ†Ô∏è Technology Stack

### Frontend
- **Three.js** (r128) - WebGL 3D graphics
- **Potree** (1.9.0) - Point cloud rendering specialist
- **Vanilla JavaScript** - No frameworks, fast and lightweight
- **CSS Grid/Flexbox** - Modern responsive layout

### Backend (Assumed)
- **AWS Lambda** - Serverless functions
- **DynamoDB** - Task metadata storage
- **S3** - Point cloud file storage
- **Cognito** - Authentication (optional)

## üìñ Usage

### Setup

1. Open `lidar-annotation.html` in browser
2. Set API Base URL: `https://api.engsitetools.com`
3. Click "Load Next Task"

### Annotation Workflow

1. **Load Task**
   - Fetches next pending annotation
   - Loads point cloud from S3
   - Loads associated photos

2. **View Data**
   - Left: Photo view (swipe through photos)
   - Right: 3D point cloud (rotate/zoom/pan)

3. **Label Points**
   - Select class from dropdown
   - Click on 3D points OR photo to select
   - Points turn colored based on class

4. **Use Auto-Detection** (optional)
   - Click "Auto-detect Pipes" ‚Üí RANSAC finds cylinders
   - Click "Auto-detect Ground" ‚Üí RANSAC finds planes
   - Review and adjust

5. **Submit**
   - Click "Submit All Labels"
   - Auto-loads next task

### Label Classes

| Class | Color | Impact | Description |
|-------|-------|--------|-------------|
| **ground** | Brown | Reference | Top of trench, reference plane |
| **pipe** | Red | Subtract | Permanent infrastructure |
| **headwall** | Red | Subtract | Permanent structure |
| **shoring** | Red | Subtract | Trench support walls |
| **person** | Orange | Ignore | Temporary, don't measure |
| **equipment** | Orange | Ignore | Temporary machinery |
| **air** | Blue | Fill | Empty space needing backfill |

## üîß API Endpoints

### GET /annotation/tasks/next
```
Response:
{
  "taskId": "task_123",
  "scanId": "scan_456",
  "pointCloudUrl": "https://s3.../scan.ply",
  "photos": [
    {"url": "https://s3.../photo1.jpg", "pose": {...}}
  ],
  "pointCount": 50000,
  "confidence": 0.45,
  "priority": "high"
}
```

### POST /annotation/tasks/{taskId}/labels
```
Request:
{
  "taskId": "task_123",
  "labels": {
    "0": "ground",
    "1": "ground",
    "5000": "pipe"
  },
  "timestamp": "2025-01-15T10:30:00Z",
  "metadata": {
    "totalLabels": 2500,
    "classes": ["ground", "pipe"]
  }
}
```

## üé® Customization

### Changing Colors

Edit `lidar-annotation.html` line ~600:
```javascript
const COLORS = {
  ground: 0x8b5e34,    // Brown
  pipe: 0xef4444,      // Red
  // ... etc
};
```

### Adding Classes

1. Add option to `<select id="labelSelect">`
2. Add color to `COLORS` object
3. Update backend enum/model

### RANSAC Parameters

Edit `ransac-helpers.js`:
```javascript
detectCylinder(points, {
  maxIterations: 1000,    // More = slower, more accurate
  inlierThreshold: 0.05,  // Distance tolerance in meters
  minInliers: 50          // Minimum points to accept
})
```

## üêõ Troubleshooting

### Point Cloud Won't Load
- Check CORS on S3 bucket
- Verify presigned URL expiration
- Check browser console for errors
- Try PLY format first (most compatible)

### Photo Click Not Working
- Ensure photo alignment data loaded
- Check camera pose in API response
- Verify photo-loader.js included

### Slow Performance
- Reduce point cloud size (decimate)
- Lower Potree quality settings
- Use fewer RANSAC iterations
- Close other browser tabs

### Backend Errors
- Verify API URL correct
- Check authentication token
- Ensure CORS configured
- Test endpoints with Postman

## üîê Security

- **Auth**: Bearer token in localStorage
- **CORS**: Configure S3 bucket properly
- **HTTPS**: Required for production
- **Rate Limits**: Implement on backend
- **Access Control**: Restrict to admins

## üìä Performance Benchmarks

| Metric | Value |
|--------|-------|
| Load time (50k points) | ~2-3s |
| FPS (Potree) | 60 fps |
| RANSAC (1000 iterations) | ~100ms |
| Submission latency | <500ms |
| Memory usage | ~150MB |

## üöß Future Enhancements

- [ ] Semantic segmentation (pixel-level)
- [ ] Instance segmentation (multiple objects)
- [ ] 3D bounding boxes
- [ ] Undo/redo history
- [ ] Keyboard shortcuts
- [ ] Batch annotation mode
- [ ] Collaborative labeling
- [ ] Model-assisted labeling
- [ ] Progress dashboard
- [ ] Export to COCO format

## üìù Notes

- **No frameworks** - Pure vanilla JS for speed and simplicity
- **Potree or Three.js** - Can switch between renderers
- **Modular design** - Each JS file is independent
- **Production-ready** - Error handling, loading states, fallbacks
- **Photo-guided** - Major time saver vs blind labeling

## üîó Related Files

- **Mobile app**: See Flutter codebase `lib/screens/ml_annotation_screen.dart`
- **Backend**: AWS Lambda functions in Amplify
- **Model training**: See ML pipeline docs
- **2D fallback**: `annotation.html` (old tool)

---

**Built for TrenchCalc ML Training Pipeline**  
**Version**: 1.0.0  
**Last Updated**: January 2025

